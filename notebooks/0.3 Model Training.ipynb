{"cells":[{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-05-03 02:47:41.829863: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2023-05-03 02:47:41.832019: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n","2023-05-03 02:47:41.879683: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n","2023-05-03 02:47:41.881072: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-05-03 02:47:42.721861: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]}],"source":["import os\n","os.environ['LD_LIBRARY_PATH'] = ':/root/.mujoco/mujoco200/bin'\n","# os.environ['LD_PRELOAD'] = ':'\n","import numpy as np\n","import robosuite as suite\n","from robosuite.utils.mjcf_utils import postprocess_model_xml\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["import os\n","import h5py\n","import argparse\n","import random"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["demo_path = '/home/ar4451/Data/RoboTurkPilot/bins-full/'\n","hdf5_path = \"/home/ar4451/Data/RoboTurkPilot/bins-full/demo.hdf5\"\n","f = h5py.File(hdf5_path, \"r\")\n","env_name = f[\"data\"].attrs[\"env\"]\n","demos = list(f[\"data\"].keys())"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["env = suite.make(\n","        env_name,\n","        has_renderer=False,\n","        ignore_done=True,\n","        use_camera_obs=False,\n","        gripper_visualization=True,\n","        reward_shaping=True,\n","        control_freq=100,\n","    )"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_8\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_24 (Dense)            (None, 512)               37888     \n","                                                                 \n"," activation_18 (Activation)  (None, 512)               0         \n","                                                                 \n"," dropout_12 (Dropout)        (None, 512)               0         \n","                                                                 \n"," dense_25 (Dense)            (None, 256)               131328    \n","                                                                 \n"," activation_19 (Activation)  (None, 256)               0         \n","                                                                 \n"," dropout_13 (Dropout)        (None, 256)               0         \n","                                                                 \n"," dense_26 (Dense)            (None, 512)               131584    \n","                                                                 \n"," activation_20 (Activation)  (None, 512)               0         \n","                                                                 \n"," dense_27 (Dense)            (None, 8)                 4104      \n","                                                                 \n","=================================================================\n","Total params: 304,904\n","Trainable params: 304,904\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["# Model Definition\n","tf_model = tf.keras.Sequential()\n","\n","tf_model.add(tf.keras.layers.Dense(512, input_shape=(73,)))\n","tf_model.add(tf.keras.layers.Activation(tf.nn.relu))\n","tf_model.add(tf.keras.layers.Dropout(0.5))\n","tf_model.add(tf.keras.layers.Dense(256))\n","tf_model.add(tf.keras.layers.Activation(tf.nn.elu))\n","tf_model.add(tf.keras.layers.Dropout(0.5))\n","tf_model.add(tf.keras.layers.Dense(512))\n","tf_model.add(tf.keras.layers.Activation(tf.nn.elu))\n","tf_model.add(tf.keras.layers.Dense(8,activation=\"softmax\",\n","    kernel_regularizer=tf.keras.regularizers.l2(l=0.01)))\n","\n","tf_model.summary()\n","tf_model.compile(loss='mean_absolute_error',\n","     optimizer='adam',\n","     metrics=['accuracy'])\n","\n","indirect_data = True"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n","17/17 [==============================] - 0s 16ms/step - loss: 0.2521 - accuracy: 0.5434 - val_loss: 0.2187 - val_accuracy: 0.5673\n","Epoch 2/30\n","17/17 [==============================] - 0s 14ms/step - loss: 0.2499 - accuracy: 0.5817 - val_loss: 0.2121 - val_accuracy: 0.6087\n","Epoch 3/30\n","17/17 [==============================] - 0s 13ms/step - loss: 0.2485 - accuracy: 0.6054 - val_loss: 0.2117 - val_accuracy: 0.6128\n","Epoch 4/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2480 - accuracy: 0.6296 - val_loss: 0.2115 - val_accuracy: 0.6190\n","Epoch 5/30\n","17/17 [==============================] - 0s 14ms/step - loss: 0.2473 - accuracy: 0.6406 - val_loss: 0.2109 - val_accuracy: 0.6253\n","Epoch 6/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2470 - accuracy: 0.6432 - val_loss: 0.2107 - val_accuracy: 0.6749\n","Epoch 7/30\n","17/17 [==============================] - 0s 11ms/step - loss: 0.2468 - accuracy: 0.6512 - val_loss: 0.2119 - val_accuracy: 0.6584\n","Epoch 8/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2465 - accuracy: 0.6413 - val_loss: 0.2137 - val_accuracy: 0.4058\n","Epoch 9/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2463 - accuracy: 0.6459 - val_loss: 0.2107 - val_accuracy: 0.4513\n","Epoch 10/30\n","17/17 [==============================] - 0s 14ms/step - loss: 0.2462 - accuracy: 0.6519 - val_loss: 0.2128 - val_accuracy: 0.6749\n","Epoch 11/30\n","17/17 [==============================] - 0s 13ms/step - loss: 0.2460 - accuracy: 0.6586 - val_loss: 0.2126 - val_accuracy: 0.5694\n","Epoch 12/30\n","17/17 [==============================] - 0s 13ms/step - loss: 0.2459 - accuracy: 0.6558 - val_loss: 0.2106 - val_accuracy: 0.6253\n","Epoch 13/30\n","17/17 [==============================] - 0s 13ms/step - loss: 0.2456 - accuracy: 0.6630 - val_loss: 0.2086 - val_accuracy: 0.6646\n","Epoch 14/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2455 - accuracy: 0.6750 - val_loss: 0.2110 - val_accuracy: 0.6046\n","Epoch 15/30\n","17/17 [==============================] - 0s 13ms/step - loss: 0.2455 - accuracy: 0.6664 - val_loss: 0.2093 - val_accuracy: 0.6398\n","Epoch 16/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2453 - accuracy: 0.6517 - val_loss: 0.2121 - val_accuracy: 0.6087\n","Epoch 17/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2452 - accuracy: 0.6713 - val_loss: 0.2094 - val_accuracy: 0.4886\n","Epoch 18/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2453 - accuracy: 0.6692 - val_loss: 0.2098 - val_accuracy: 0.5507\n","Epoch 19/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2448 - accuracy: 0.6717 - val_loss: 0.2087 - val_accuracy: 0.6646\n","Epoch 20/30\n","17/17 [==============================] - 0s 11ms/step - loss: 0.2453 - accuracy: 0.6623 - val_loss: 0.2117 - val_accuracy: 0.6315\n","Epoch 21/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2451 - accuracy: 0.6821 - val_loss: 0.2113 - val_accuracy: 0.6025\n","Epoch 22/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2452 - accuracy: 0.6554 - val_loss: 0.2085 - val_accuracy: 0.7764\n","Epoch 23/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2450 - accuracy: 0.6708 - val_loss: 0.2087 - val_accuracy: 0.6812\n","Epoch 24/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2449 - accuracy: 0.6816 - val_loss: 0.2089 - val_accuracy: 0.7226\n","Epoch 25/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2447 - accuracy: 0.6768 - val_loss: 0.2119 - val_accuracy: 0.4907\n","Epoch 26/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2446 - accuracy: 0.6754 - val_loss: 0.2090 - val_accuracy: 0.5652\n","Epoch 27/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2447 - accuracy: 0.6731 - val_loss: 0.2087 - val_accuracy: 0.4327\n","Epoch 28/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2445 - accuracy: 0.6853 - val_loss: 0.2090 - val_accuracy: 0.6253\n","Epoch 29/30\n","17/17 [==============================] - 0s 13ms/step - loss: 0.2445 - accuracy: 0.6782 - val_loss: 0.2114 - val_accuracy: 0.4990\n","Epoch 30/30\n","17/17 [==============================] - 0s 13ms/step - loss: 0.2444 - accuracy: 0.6648 - val_loss: 0.2093 - val_accuracy: 0.6335\n","Epoch 1/30\n","21/21 [==============================] - 0s 14ms/step - loss: 0.2528 - accuracy: 0.5534 - val_loss: 0.2119 - val_accuracy: 0.4863\n","Epoch 2/30\n","21/21 [==============================] - 0s 12ms/step - loss: 0.2503 - accuracy: 0.5696 - val_loss: 0.2167 - val_accuracy: 0.4588\n","Epoch 3/30\n","21/21 [==============================] - 0s 11ms/step - loss: 0.2496 - accuracy: 0.5857 - val_loss: 0.2142 - val_accuracy: 0.5069\n","Epoch 4/30\n","21/21 [==============================] - 0s 11ms/step - loss: 0.2489 - accuracy: 0.5948 - val_loss: 0.2125 - val_accuracy: 0.6856\n","Epoch 5/30\n","21/21 [==============================] - 0s 12ms/step - loss: 0.2491 - accuracy: 0.5933 - val_loss: 0.2125 - val_accuracy: 0.5241\n","Epoch 6/30\n","21/21 [==============================] - 0s 12ms/step - loss: 0.2482 - accuracy: 0.6027 - val_loss: 0.2135 - val_accuracy: 0.5223\n","Epoch 7/30\n","21/21 [==============================] - 0s 11ms/step - loss: 0.2480 - accuracy: 0.6048 - val_loss: 0.2132 - val_accuracy: 0.4828\n","Epoch 8/30\n","21/21 [==============================] - 0s 11ms/step - loss: 0.2479 - accuracy: 0.6027 - val_loss: 0.2125 - val_accuracy: 0.5275\n","Epoch 9/30\n","21/21 [==============================] - 0s 11ms/step - loss: 0.2477 - accuracy: 0.6204 - val_loss: 0.2154 - val_accuracy: 0.5430\n","Epoch 10/30\n","21/21 [==============================] - 0s 11ms/step - loss: 0.2475 - accuracy: 0.6025 - val_loss: 0.2120 - val_accuracy: 0.6546\n","Epoch 11/30\n","21/21 [==============================] - 0s 11ms/step - loss: 0.2474 - accuracy: 0.6141 - val_loss: 0.2138 - val_accuracy: 0.5189\n","Epoch 12/30\n","21/21 [==============================] - 0s 12ms/step - loss: 0.2471 - accuracy: 0.6141 - val_loss: 0.2121 - val_accuracy: 0.5309\n","Epoch 13/30\n","21/21 [==============================] - 0s 11ms/step - loss: 0.2471 - accuracy: 0.6170 - val_loss: 0.2125 - val_accuracy: 0.6048\n","Epoch 14/30\n","21/21 [==============================] - 0s 12ms/step - loss: 0.2468 - accuracy: 0.6214 - val_loss: 0.2125 - val_accuracy: 0.5722\n","Epoch 15/30\n","21/21 [==============================] - 0s 11ms/step - loss: 0.2469 - accuracy: 0.6202 - val_loss: 0.2133 - val_accuracy: 0.5103\n","Epoch 16/30\n","21/21 [==============================] - 0s 11ms/step - loss: 0.2466 - accuracy: 0.6139 - val_loss: 0.2127 - val_accuracy: 0.4966\n","Epoch 17/30\n","21/21 [==============================] - 0s 12ms/step - loss: 0.2464 - accuracy: 0.6222 - val_loss: 0.2150 - val_accuracy: 0.5103\n","Epoch 18/30\n","21/21 [==============================] - 0s 13ms/step - loss: 0.2465 - accuracy: 0.6220 - val_loss: 0.2137 - val_accuracy: 0.4725\n","Epoch 19/30\n","21/21 [==============================] - 0s 11ms/step - loss: 0.2463 - accuracy: 0.6197 - val_loss: 0.2118 - val_accuracy: 0.5120\n","Epoch 20/30\n","21/21 [==============================] - 0s 12ms/step - loss: 0.2463 - accuracy: 0.6187 - val_loss: 0.2127 - val_accuracy: 0.5189\n","Epoch 21/30\n","21/21 [==============================] - 0s 13ms/step - loss: 0.2465 - accuracy: 0.6248 - val_loss: 0.2127 - val_accuracy: 0.5361\n","Epoch 22/30\n","21/21 [==============================] - 0s 12ms/step - loss: 0.2462 - accuracy: 0.6275 - val_loss: 0.2119 - val_accuracy: 0.4759\n","Epoch 23/30\n","21/21 [==============================] - 0s 12ms/step - loss: 0.2461 - accuracy: 0.6269 - val_loss: 0.2123 - val_accuracy: 0.6495\n","Epoch 24/30\n","21/21 [==============================] - 0s 12ms/step - loss: 0.2461 - accuracy: 0.6246 - val_loss: 0.2116 - val_accuracy: 0.4880\n","Epoch 25/30\n","21/21 [==============================] - 0s 13ms/step - loss: 0.2461 - accuracy: 0.6220 - val_loss: 0.2111 - val_accuracy: 0.4845\n","Epoch 26/30\n","21/21 [==============================] - 0s 14ms/step - loss: 0.2459 - accuracy: 0.6201 - val_loss: 0.2113 - val_accuracy: 0.6168\n","Epoch 27/30\n","21/21 [==============================] - 0s 13ms/step - loss: 0.2459 - accuracy: 0.6252 - val_loss: 0.2117 - val_accuracy: 0.5241\n","Epoch 28/30\n","21/21 [==============================] - 0s 13ms/step - loss: 0.2458 - accuracy: 0.6218 - val_loss: 0.2118 - val_accuracy: 0.5430\n","Epoch 29/30\n","21/21 [==============================] - 0s 13ms/step - loss: 0.2456 - accuracy: 0.6308 - val_loss: 0.2124 - val_accuracy: 0.5155\n","Epoch 30/30\n","21/21 [==============================] - 0s 11ms/step - loss: 0.2458 - accuracy: 0.6300 - val_loss: 0.2118 - val_accuracy: 0.5395\n","Epoch 1/30\n","11/11 [==============================] - 0s 17ms/step - loss: 0.2645 - accuracy: 0.5926 - val_loss: 0.1801 - val_accuracy: 0.7213\n","Epoch 2/30\n","11/11 [==============================] - 0s 12ms/step - loss: 0.2611 - accuracy: 0.6509 - val_loss: 0.1791 - val_accuracy: 0.7213\n","Epoch 3/30\n","11/11 [==============================] - 0s 13ms/step - loss: 0.2602 - accuracy: 0.6586 - val_loss: 0.1791 - val_accuracy: 0.6899\n","Epoch 4/30\n","11/11 [==============================] - 0s 13ms/step - loss: 0.2595 - accuracy: 0.6637 - val_loss: 0.1801 - val_accuracy: 0.6028\n","Epoch 5/30\n","11/11 [==============================] - 0s 12ms/step - loss: 0.2599 - accuracy: 0.6583 - val_loss: 0.1839 - val_accuracy: 0.5470\n","Epoch 6/30\n","11/11 [==============================] - 0s 13ms/step - loss: 0.2611 - accuracy: 0.6249 - val_loss: 0.1830 - val_accuracy: 0.4878\n","Epoch 7/30\n","11/11 [==============================] - 0s 14ms/step - loss: 0.2595 - accuracy: 0.6458 - val_loss: 0.1838 - val_accuracy: 0.3798\n","Epoch 8/30\n","11/11 [==============================] - 0s 14ms/step - loss: 0.2598 - accuracy: 0.6520 - val_loss: 0.1827 - val_accuracy: 0.5610\n","Epoch 9/30\n","11/11 [==============================] - 0s 12ms/step - loss: 0.2587 - accuracy: 0.6715 - val_loss: 0.1789 - val_accuracy: 0.5714\n","Epoch 10/30\n","11/11 [==============================] - 0s 12ms/step - loss: 0.2585 - accuracy: 0.6610 - val_loss: 0.1811 - val_accuracy: 0.6411\n","Epoch 11/30\n","11/11 [==============================] - 0s 12ms/step - loss: 0.2583 - accuracy: 0.6753 - val_loss: 0.1841 - val_accuracy: 0.4321\n","Epoch 12/30\n","11/11 [==============================] - 0s 12ms/step - loss: 0.2584 - accuracy: 0.6738 - val_loss: 0.1806 - val_accuracy: 0.6411\n","Epoch 13/30\n","11/11 [==============================] - 0s 12ms/step - loss: 0.2578 - accuracy: 0.6676 - val_loss: 0.1810 - val_accuracy: 0.5993\n","Epoch 14/30\n","11/11 [==============================] - 0s 12ms/step - loss: 0.2572 - accuracy: 0.6738 - val_loss: 0.1833 - val_accuracy: 0.5122\n","Epoch 15/30\n","11/11 [==============================] - 0s 13ms/step - loss: 0.2578 - accuracy: 0.6691 - val_loss: 0.1846 - val_accuracy: 0.4774\n","Epoch 16/30\n","11/11 [==============================] - 0s 12ms/step - loss: 0.2570 - accuracy: 0.6746 - val_loss: 0.1833 - val_accuracy: 0.4146\n","Epoch 17/30\n","11/11 [==============================] - 0s 13ms/step - loss: 0.2568 - accuracy: 0.6676 - val_loss: 0.1868 - val_accuracy: 0.3380\n","Epoch 18/30\n","11/11 [==============================] - 0s 12ms/step - loss: 0.2586 - accuracy: 0.6594 - val_loss: 0.1840 - val_accuracy: 0.5540\n","Epoch 19/30\n","11/11 [==============================] - 0s 13ms/step - loss: 0.2583 - accuracy: 0.6435 - val_loss: 0.1833 - val_accuracy: 0.4216\n","Epoch 20/30\n","11/11 [==============================] - 0s 13ms/step - loss: 0.2576 - accuracy: 0.6637 - val_loss: 0.1834 - val_accuracy: 0.5505\n","Epoch 21/30\n","11/11 [==============================] - 0s 13ms/step - loss: 0.2573 - accuracy: 0.6699 - val_loss: 0.1801 - val_accuracy: 0.7805\n","Epoch 22/30\n","11/11 [==============================] - 0s 13ms/step - loss: 0.2569 - accuracy: 0.6645 - val_loss: 0.1815 - val_accuracy: 0.5993\n","Epoch 23/30\n","11/11 [==============================] - 0s 13ms/step - loss: 0.2563 - accuracy: 0.6656 - val_loss: 0.1829 - val_accuracy: 0.4843\n","Epoch 24/30\n","11/11 [==============================] - 0s 14ms/step - loss: 0.2573 - accuracy: 0.6583 - val_loss: 0.1804 - val_accuracy: 0.6098\n","Epoch 25/30\n","11/11 [==============================] - 0s 12ms/step - loss: 0.2565 - accuracy: 0.6781 - val_loss: 0.1814 - val_accuracy: 0.5122\n","Epoch 26/30\n","11/11 [==============================] - 0s 13ms/step - loss: 0.2573 - accuracy: 0.6544 - val_loss: 0.1834 - val_accuracy: 0.4983\n","Epoch 27/30\n","11/11 [==============================] - 0s 13ms/step - loss: 0.2566 - accuracy: 0.6971 - val_loss: 0.1835 - val_accuracy: 0.4983\n","Epoch 28/30\n","11/11 [==============================] - 0s 13ms/step - loss: 0.2566 - accuracy: 0.6718 - val_loss: 0.1806 - val_accuracy: 0.5401\n","Epoch 29/30\n","11/11 [==============================] - 0s 13ms/step - loss: 0.2561 - accuracy: 0.6917 - val_loss: 0.1816 - val_accuracy: 0.5261\n","Epoch 30/30\n","11/11 [==============================] - 0s 14ms/step - loss: 0.2557 - accuracy: 0.6753 - val_loss: 0.1819 - val_accuracy: 0.5052\n","Epoch 1/30\n","18/18 [==============================] - 0s 14ms/step - loss: 0.2414 - accuracy: 0.5700 - val_loss: 0.2157 - val_accuracy: 0.5451\n","Epoch 2/30\n","18/18 [==============================] - 0s 12ms/step - loss: 0.2380 - accuracy: 0.6206 - val_loss: 0.2227 - val_accuracy: 0.3934\n","Epoch 3/30\n","18/18 [==============================] - 0s 11ms/step - loss: 0.2373 - accuracy: 0.6243 - val_loss: 0.2190 - val_accuracy: 0.5082\n","Epoch 4/30\n","18/18 [==============================] - 0s 12ms/step - loss: 0.2368 - accuracy: 0.6530 - val_loss: 0.2196 - val_accuracy: 0.4959\n","Epoch 5/30\n","18/18 [==============================] - 0s 12ms/step - loss: 0.2362 - accuracy: 0.6464 - val_loss: 0.2161 - val_accuracy: 0.4980\n","Epoch 6/30\n","18/18 [==============================] - 0s 12ms/step - loss: 0.2354 - accuracy: 0.6658 - val_loss: 0.2163 - val_accuracy: 0.6148\n","Epoch 7/30\n","18/18 [==============================] - 0s 12ms/step - loss: 0.2352 - accuracy: 0.6607 - val_loss: 0.2123 - val_accuracy: 0.6045\n","Epoch 8/30\n","18/18 [==============================] - 0s 12ms/step - loss: 0.2350 - accuracy: 0.6685 - val_loss: 0.2250 - val_accuracy: 0.4734\n","Epoch 9/30\n","18/18 [==============================] - 0s 12ms/step - loss: 0.2351 - accuracy: 0.6550 - val_loss: 0.2172 - val_accuracy: 0.4734\n","Epoch 10/30\n","18/18 [==============================] - 0s 12ms/step - loss: 0.2354 - accuracy: 0.6623 - val_loss: 0.2268 - val_accuracy: 0.4365\n","Epoch 11/30\n","18/18 [==============================] - 0s 11ms/step - loss: 0.2348 - accuracy: 0.6514 - val_loss: 0.2174 - val_accuracy: 0.5266\n","Epoch 12/30\n","18/18 [==============================] - 0s 12ms/step - loss: 0.2347 - accuracy: 0.6680 - val_loss: 0.2220 - val_accuracy: 0.4488\n","Epoch 13/30\n","18/18 [==============================] - 0s 11ms/step - loss: 0.2349 - accuracy: 0.6557 - val_loss: 0.2139 - val_accuracy: 0.5123\n","Epoch 14/30\n","18/18 [==============================] - 0s 11ms/step - loss: 0.2346 - accuracy: 0.6829 - val_loss: 0.2172 - val_accuracy: 0.4426\n","Epoch 15/30\n","18/18 [==============================] - 0s 12ms/step - loss: 0.2344 - accuracy: 0.6895 - val_loss: 0.2180 - val_accuracy: 0.5861\n","Epoch 16/30\n","18/18 [==============================] - 0s 12ms/step - loss: 0.2346 - accuracy: 0.6715 - val_loss: 0.2093 - val_accuracy: 0.6414\n","Epoch 17/30\n","18/18 [==============================] - 0s 12ms/step - loss: 0.2341 - accuracy: 0.6865 - val_loss: 0.2160 - val_accuracy: 0.5000\n","Epoch 18/30\n","18/18 [==============================] - 0s 11ms/step - loss: 0.2345 - accuracy: 0.6772 - val_loss: 0.2208 - val_accuracy: 0.5246\n","Epoch 19/30\n","18/18 [==============================] - 0s 11ms/step - loss: 0.2339 - accuracy: 0.6721 - val_loss: 0.2187 - val_accuracy: 0.5061\n","Epoch 20/30\n","18/18 [==============================] - 0s 11ms/step - loss: 0.2335 - accuracy: 0.6897 - val_loss: 0.2156 - val_accuracy: 0.5389\n","Epoch 21/30\n","18/18 [==============================] - 0s 11ms/step - loss: 0.2336 - accuracy: 0.6788 - val_loss: 0.2176 - val_accuracy: 0.5205\n","Epoch 22/30\n","18/18 [==============================] - 0s 11ms/step - loss: 0.2338 - accuracy: 0.6767 - val_loss: 0.2126 - val_accuracy: 0.4508\n","Epoch 23/30\n","18/18 [==============================] - 0s 11ms/step - loss: 0.2340 - accuracy: 0.6760 - val_loss: 0.2169 - val_accuracy: 0.5615\n","Epoch 24/30\n","18/18 [==============================] - 0s 12ms/step - loss: 0.2340 - accuracy: 0.6897 - val_loss: 0.2188 - val_accuracy: 0.5533\n","Epoch 25/30\n","18/18 [==============================] - 0s 12ms/step - loss: 0.2337 - accuracy: 0.6680 - val_loss: 0.2229 - val_accuracy: 0.5000\n","Epoch 26/30\n","18/18 [==============================] - 0s 11ms/step - loss: 0.2336 - accuracy: 0.6854 - val_loss: 0.2187 - val_accuracy: 0.5881\n","Epoch 27/30\n","18/18 [==============================] - 0s 12ms/step - loss: 0.2336 - accuracy: 0.6708 - val_loss: 0.2153 - val_accuracy: 0.5963\n","Epoch 28/30\n","18/18 [==============================] - 0s 12ms/step - loss: 0.2331 - accuracy: 0.6858 - val_loss: 0.2147 - val_accuracy: 0.5164\n","Epoch 29/30\n","18/18 [==============================] - 0s 11ms/step - loss: 0.2334 - accuracy: 0.6902 - val_loss: 0.2123 - val_accuracy: 0.6578\n","Epoch 30/30\n","18/18 [==============================] - 0s 11ms/step - loss: 0.2333 - accuracy: 0.6831 - val_loss: 0.2208 - val_accuracy: 0.5205\n","Epoch 1/30\n","12/12 [==============================] - 0s 18ms/step - loss: 0.2678 - accuracy: 0.5519 - val_loss: 0.2497 - val_accuracy: 0.4441\n","Epoch 2/30\n","12/12 [==============================] - 0s 13ms/step - loss: 0.2655 - accuracy: 0.5699 - val_loss: 0.2536 - val_accuracy: 0.4059\n","Epoch 3/30\n","12/12 [==============================] - 0s 13ms/step - loss: 0.2648 - accuracy: 0.5762 - val_loss: 0.2509 - val_accuracy: 0.4853\n","Epoch 4/30\n","12/12 [==============================] - 0s 13ms/step - loss: 0.2636 - accuracy: 0.5952 - val_loss: 0.2528 - val_accuracy: 0.4941\n","Epoch 5/30\n","12/12 [==============================] - 0s 13ms/step - loss: 0.2632 - accuracy: 0.5994 - val_loss: 0.2494 - val_accuracy: 0.4471\n","Epoch 6/30\n","12/12 [==============================] - 0s 14ms/step - loss: 0.2630 - accuracy: 0.5889 - val_loss: 0.2501 - val_accuracy: 0.4647\n","Epoch 7/30\n","12/12 [==============================] - 0s 13ms/step - loss: 0.2626 - accuracy: 0.6053 - val_loss: 0.2488 - val_accuracy: 0.4176\n","Epoch 8/30\n","12/12 [==============================] - 0s 13ms/step - loss: 0.2625 - accuracy: 0.6024 - val_loss: 0.2517 - val_accuracy: 0.4676\n","Epoch 9/30\n","12/12 [==============================] - 0s 13ms/step - loss: 0.2620 - accuracy: 0.6194 - val_loss: 0.2501 - val_accuracy: 0.4912\n","Epoch 10/30\n","12/12 [==============================] - 0s 14ms/step - loss: 0.2617 - accuracy: 0.6158 - val_loss: 0.2499 - val_accuracy: 0.5059\n","Epoch 11/30\n","12/12 [==============================] - 0s 13ms/step - loss: 0.2620 - accuracy: 0.6043 - val_loss: 0.2530 - val_accuracy: 0.4206\n","Epoch 12/30\n","12/12 [==============================] - 0s 13ms/step - loss: 0.2618 - accuracy: 0.6184 - val_loss: 0.2486 - val_accuracy: 0.4735\n","Epoch 13/30\n","12/12 [==============================] - 0s 13ms/step - loss: 0.2614 - accuracy: 0.6289 - val_loss: 0.2513 - val_accuracy: 0.4971\n","Epoch 14/30\n","12/12 [==============================] - 0s 13ms/step - loss: 0.2610 - accuracy: 0.6348 - val_loss: 0.2497 - val_accuracy: 0.4588\n","Epoch 15/30\n","12/12 [==============================] - 0s 16ms/step - loss: 0.2613 - accuracy: 0.6194 - val_loss: 0.2507 - val_accuracy: 0.4353\n","Epoch 16/30\n","12/12 [==============================] - 0s 12ms/step - loss: 0.2611 - accuracy: 0.6194 - val_loss: 0.2498 - val_accuracy: 0.4000\n","Epoch 17/30\n","12/12 [==============================] - 0s 13ms/step - loss: 0.2612 - accuracy: 0.6223 - val_loss: 0.2490 - val_accuracy: 0.5206\n","Epoch 18/30\n","12/12 [==============================] - 0s 13ms/step - loss: 0.2611 - accuracy: 0.6309 - val_loss: 0.2509 - val_accuracy: 0.4647\n","Epoch 19/30\n","12/12 [==============================] - 0s 15ms/step - loss: 0.2608 - accuracy: 0.6410 - val_loss: 0.2508 - val_accuracy: 0.4706\n","Epoch 20/30\n","12/12 [==============================] - 0s 14ms/step - loss: 0.2607 - accuracy: 0.6358 - val_loss: 0.2505 - val_accuracy: 0.4765\n","Epoch 21/30\n","12/12 [==============================] - 0s 16ms/step - loss: 0.2609 - accuracy: 0.6161 - val_loss: 0.2528 - val_accuracy: 0.4588\n","Epoch 22/30\n","12/12 [==============================] - 0s 14ms/step - loss: 0.2609 - accuracy: 0.6292 - val_loss: 0.2505 - val_accuracy: 0.4941\n","Epoch 23/30\n","12/12 [==============================] - 0s 13ms/step - loss: 0.2607 - accuracy: 0.6351 - val_loss: 0.2496 - val_accuracy: 0.5059\n","Epoch 24/30\n","12/12 [==============================] - 0s 13ms/step - loss: 0.2607 - accuracy: 0.6233 - val_loss: 0.2527 - val_accuracy: 0.4765\n","Epoch 25/30\n","12/12 [==============================] - 0s 12ms/step - loss: 0.2608 - accuracy: 0.6318 - val_loss: 0.2518 - val_accuracy: 0.4412\n","Epoch 26/30\n","12/12 [==============================] - 0s 12ms/step - loss: 0.2607 - accuracy: 0.6312 - val_loss: 0.2498 - val_accuracy: 0.5559\n","Epoch 27/30\n","12/12 [==============================] - 0s 13ms/step - loss: 0.2604 - accuracy: 0.6345 - val_loss: 0.2528 - val_accuracy: 0.5294\n","Epoch 28/30\n","12/12 [==============================] - 0s 14ms/step - loss: 0.2605 - accuracy: 0.6390 - val_loss: 0.2524 - val_accuracy: 0.4971\n","Epoch 29/30\n","12/12 [==============================] - 0s 13ms/step - loss: 0.2602 - accuracy: 0.6440 - val_loss: 0.2508 - val_accuracy: 0.4971\n","Epoch 30/30\n","12/12 [==============================] - 0s 12ms/step - loss: 0.2602 - accuracy: 0.6338 - val_loss: 0.2515 - val_accuracy: 0.5235\n","Epoch 1/30\n","17/17 [==============================] - 0s 14ms/step - loss: 0.2823 - accuracy: 0.5426 - val_loss: 0.3052 - val_accuracy: 0.6205\n","Epoch 2/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2732 - accuracy: 0.6132 - val_loss: 0.3121 - val_accuracy: 0.5618\n","Epoch 3/30\n","17/17 [==============================] - 0s 13ms/step - loss: 0.2684 - accuracy: 0.6554 - val_loss: 0.3029 - val_accuracy: 0.5639\n","Epoch 4/30\n","17/17 [==============================] - 0s 13ms/step - loss: 0.2658 - accuracy: 0.6685 - val_loss: 0.3023 - val_accuracy: 0.5493\n","Epoch 5/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2642 - accuracy: 0.6831 - val_loss: 0.3011 - val_accuracy: 0.6101\n","Epoch 6/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2629 - accuracy: 0.7009 - val_loss: 0.3035 - val_accuracy: 0.5073\n","Epoch 7/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2617 - accuracy: 0.7058 - val_loss: 0.3001 - val_accuracy: 0.5807\n","Epoch 8/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2606 - accuracy: 0.7342 - val_loss: 0.2999 - val_accuracy: 0.6059\n","Epoch 9/30\n","17/17 [==============================] - 0s 13ms/step - loss: 0.2598 - accuracy: 0.7218 - val_loss: 0.3060 - val_accuracy: 0.5052\n","Epoch 10/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2587 - accuracy: 0.7309 - val_loss: 0.3027 - val_accuracy: 0.6038\n","Epoch 11/30\n","17/17 [==============================] - 0s 13ms/step - loss: 0.2581 - accuracy: 0.7358 - val_loss: 0.2969 - val_accuracy: 0.5996\n","Epoch 12/30\n","17/17 [==============================] - 0s 13ms/step - loss: 0.2575 - accuracy: 0.7501 - val_loss: 0.3023 - val_accuracy: 0.6059\n","Epoch 13/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2572 - accuracy: 0.7456 - val_loss: 0.2986 - val_accuracy: 0.5954\n","Epoch 14/30\n","17/17 [==============================] - 0s 11ms/step - loss: 0.2572 - accuracy: 0.7552 - val_loss: 0.3001 - val_accuracy: 0.5870\n","Epoch 15/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2566 - accuracy: 0.7566 - val_loss: 0.3006 - val_accuracy: 0.5409\n","Epoch 16/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2562 - accuracy: 0.7582 - val_loss: 0.2956 - val_accuracy: 0.6080\n","Epoch 17/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2560 - accuracy: 0.7564 - val_loss: 0.2992 - val_accuracy: 0.6205\n","Epoch 18/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2561 - accuracy: 0.7550 - val_loss: 0.2975 - val_accuracy: 0.5870\n","Epoch 19/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2558 - accuracy: 0.7477 - val_loss: 0.2941 - val_accuracy: 0.6184\n","Epoch 20/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2552 - accuracy: 0.7566 - val_loss: 0.3026 - val_accuracy: 0.5660\n","Epoch 21/30\n","17/17 [==============================] - 0s 13ms/step - loss: 0.2550 - accuracy: 0.7582 - val_loss: 0.3017 - val_accuracy: 0.5786\n","Epoch 22/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2544 - accuracy: 0.7689 - val_loss: 0.3023 - val_accuracy: 0.5765\n","Epoch 23/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2543 - accuracy: 0.7741 - val_loss: 0.2961 - val_accuracy: 0.6122\n","Epoch 24/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2544 - accuracy: 0.7671 - val_loss: 0.2985 - val_accuracy: 0.5849\n","Epoch 25/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2539 - accuracy: 0.7652 - val_loss: 0.3020 - val_accuracy: 0.5807\n","Epoch 26/30\n","17/17 [==============================] - 0s 13ms/step - loss: 0.2537 - accuracy: 0.7601 - val_loss: 0.2996 - val_accuracy: 0.5472\n","Epoch 27/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2532 - accuracy: 0.7827 - val_loss: 0.2967 - val_accuracy: 0.6226\n","Epoch 28/30\n","17/17 [==============================] - 0s 13ms/step - loss: 0.2535 - accuracy: 0.7671 - val_loss: 0.3014 - val_accuracy: 0.5723\n","Epoch 29/30\n","17/17 [==============================] - 0s 14ms/step - loss: 0.2529 - accuracy: 0.7750 - val_loss: 0.2989 - val_accuracy: 0.5912\n","Epoch 30/30\n","17/17 [==============================] - 0s 13ms/step - loss: 0.2532 - accuracy: 0.7615 - val_loss: 0.2993 - val_accuracy: 0.6101\n","Epoch 1/30\n","19/19 [==============================] - 0s 15ms/step - loss: 0.2543 - accuracy: 0.4745 - val_loss: 0.1961 - val_accuracy: 0.4785\n","Epoch 2/30\n","19/19 [==============================] - 0s 12ms/step - loss: 0.2493 - accuracy: 0.5340 - val_loss: 0.1939 - val_accuracy: 0.4374\n","Epoch 3/30\n","19/19 [==============================] - 0s 11ms/step - loss: 0.2481 - accuracy: 0.5600 - val_loss: 0.1923 - val_accuracy: 0.5664\n","Epoch 4/30\n","19/19 [==============================] - 0s 13ms/step - loss: 0.2480 - accuracy: 0.5330 - val_loss: 0.1923 - val_accuracy: 0.4785\n","Epoch 5/30\n","19/19 [==============================] - 0s 12ms/step - loss: 0.2476 - accuracy: 0.5496 - val_loss: 0.1930 - val_accuracy: 0.4654\n","Epoch 6/30\n","19/19 [==============================] - 0s 12ms/step - loss: 0.2474 - accuracy: 0.5151 - val_loss: 0.1926 - val_accuracy: 0.5383\n","Epoch 7/30\n","19/19 [==============================] - 0s 13ms/step - loss: 0.2470 - accuracy: 0.5446 - val_loss: 0.1922 - val_accuracy: 0.5103\n","Epoch 8/30\n","19/19 [==============================] - 0s 13ms/step - loss: 0.2471 - accuracy: 0.5428 - val_loss: 0.1949 - val_accuracy: 0.4393\n","Epoch 9/30\n","19/19 [==============================] - 0s 14ms/step - loss: 0.2470 - accuracy: 0.5367 - val_loss: 0.1922 - val_accuracy: 0.5308\n","Epoch 10/30\n","19/19 [==============================] - 0s 12ms/step - loss: 0.2470 - accuracy: 0.5346 - val_loss: 0.1951 - val_accuracy: 0.4131\n","Epoch 11/30\n","19/19 [==============================] - 0s 12ms/step - loss: 0.2471 - accuracy: 0.5513 - val_loss: 0.1934 - val_accuracy: 0.2710\n","Epoch 12/30\n","19/19 [==============================] - 0s 13ms/step - loss: 0.2470 - accuracy: 0.5463 - val_loss: 0.1935 - val_accuracy: 0.5364\n","Epoch 13/30\n","19/19 [==============================] - 0s 12ms/step - loss: 0.2468 - accuracy: 0.5348 - val_loss: 0.1945 - val_accuracy: 0.4280\n","Epoch 14/30\n","19/19 [==============================] - 0s 12ms/step - loss: 0.2465 - accuracy: 0.5442 - val_loss: 0.1926 - val_accuracy: 0.5121\n","Epoch 15/30\n","19/19 [==============================] - 0s 12ms/step - loss: 0.2467 - accuracy: 0.5361 - val_loss: 0.1947 - val_accuracy: 0.5327\n","Epoch 16/30\n","19/19 [==============================] - 0s 12ms/step - loss: 0.2465 - accuracy: 0.5409 - val_loss: 0.1930 - val_accuracy: 0.5271\n","Epoch 17/30\n","19/19 [==============================] - 0s 12ms/step - loss: 0.2465 - accuracy: 0.5371 - val_loss: 0.1943 - val_accuracy: 0.4336\n","Epoch 18/30\n","19/19 [==============================] - 0s 12ms/step - loss: 0.2465 - accuracy: 0.5438 - val_loss: 0.1939 - val_accuracy: 0.5196\n","Epoch 19/30\n","19/19 [==============================] - 0s 12ms/step - loss: 0.2464 - accuracy: 0.5357 - val_loss: 0.1934 - val_accuracy: 0.5383\n","Epoch 20/30\n","19/19 [==============================] - 0s 12ms/step - loss: 0.2466 - accuracy: 0.5415 - val_loss: 0.1954 - val_accuracy: 0.4972\n","Epoch 21/30\n","19/19 [==============================] - 0s 12ms/step - loss: 0.2464 - accuracy: 0.5492 - val_loss: 0.1941 - val_accuracy: 0.4262\n","Epoch 22/30\n","19/19 [==============================] - 0s 12ms/step - loss: 0.2465 - accuracy: 0.5315 - val_loss: 0.1927 - val_accuracy: 0.3103\n","Epoch 23/30\n","19/19 [==============================] - 0s 12ms/step - loss: 0.2463 - accuracy: 0.5417 - val_loss: 0.1929 - val_accuracy: 0.3215\n","Epoch 24/30\n","19/19 [==============================] - 0s 12ms/step - loss: 0.2464 - accuracy: 0.5428 - val_loss: 0.1933 - val_accuracy: 0.5533\n","Epoch 25/30\n","19/19 [==============================] - 0s 12ms/step - loss: 0.2463 - accuracy: 0.5388 - val_loss: 0.1927 - val_accuracy: 0.3290\n","Epoch 26/30\n","19/19 [==============================] - 0s 12ms/step - loss: 0.2464 - accuracy: 0.5548 - val_loss: 0.1956 - val_accuracy: 0.5234\n","Epoch 27/30\n","19/19 [==============================] - 0s 12ms/step - loss: 0.2462 - accuracy: 0.5255 - val_loss: 0.1941 - val_accuracy: 0.3271\n","Epoch 28/30\n","19/19 [==============================] - 0s 12ms/step - loss: 0.2462 - accuracy: 0.5340 - val_loss: 0.1942 - val_accuracy: 0.3196\n","Epoch 29/30\n","19/19 [==============================] - 0s 13ms/step - loss: 0.2462 - accuracy: 0.5434 - val_loss: 0.1943 - val_accuracy: 0.3477\n","Epoch 30/30\n","19/19 [==============================] - 0s 12ms/step - loss: 0.2461 - accuracy: 0.5403 - val_loss: 0.1953 - val_accuracy: 0.3196\n","Epoch 1/30\n","17/17 [==============================] - 0s 14ms/step - loss: 0.2644 - accuracy: 0.5141 - val_loss: 0.2393 - val_accuracy: 0.4642\n","Epoch 2/30\n","17/17 [==============================] - 0s 11ms/step - loss: 0.2629 - accuracy: 0.4789 - val_loss: 0.2381 - val_accuracy: 0.4469\n","Epoch 3/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2620 - accuracy: 0.4705 - val_loss: 0.2368 - val_accuracy: 0.5813\n","Epoch 4/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2615 - accuracy: 0.4775 - val_loss: 0.2370 - val_accuracy: 0.6811\n","Epoch 5/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2615 - accuracy: 0.4975 - val_loss: 0.2372 - val_accuracy: 0.6356\n","Epoch 6/30\n","17/17 [==============================] - 0s 11ms/step - loss: 0.2613 - accuracy: 0.4799 - val_loss: 0.2389 - val_accuracy: 0.6616\n","Epoch 7/30\n","17/17 [==============================] - 0s 11ms/step - loss: 0.2615 - accuracy: 0.5025 - val_loss: 0.2371 - val_accuracy: 0.5857\n","Epoch 8/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2612 - accuracy: 0.4796 - val_loss: 0.2380 - val_accuracy: 0.6551\n","Epoch 9/30\n","17/17 [==============================] - 0s 11ms/step - loss: 0.2611 - accuracy: 0.5090 - val_loss: 0.2376 - val_accuracy: 0.6161\n","Epoch 10/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2608 - accuracy: 0.4734 - val_loss: 0.2377 - val_accuracy: 0.4794\n","Epoch 11/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2607 - accuracy: 0.4762 - val_loss: 0.2367 - val_accuracy: 0.6161\n","Epoch 12/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2606 - accuracy: 0.4929 - val_loss: 0.2370 - val_accuracy: 0.5835\n","Epoch 13/30\n","17/17 [==============================] - 0s 13ms/step - loss: 0.2605 - accuracy: 0.5136 - val_loss: 0.2373 - val_accuracy: 0.6529\n","Epoch 14/30\n","17/17 [==============================] - 0s 13ms/step - loss: 0.2603 - accuracy: 0.5223 - val_loss: 0.2373 - val_accuracy: 0.6638\n","Epoch 15/30\n","17/17 [==============================] - 0s 13ms/step - loss: 0.2602 - accuracy: 0.4982 - val_loss: 0.2378 - val_accuracy: 0.6443\n","Epoch 16/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2604 - accuracy: 0.5025 - val_loss: 0.2380 - val_accuracy: 0.6638\n","Epoch 17/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2607 - accuracy: 0.4984 - val_loss: 0.2368 - val_accuracy: 0.6009\n","Epoch 18/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2607 - accuracy: 0.4972 - val_loss: 0.2374 - val_accuracy: 0.5336\n","Epoch 19/30\n","17/17 [==============================] - 0s 13ms/step - loss: 0.2603 - accuracy: 0.5033 - val_loss: 0.2366 - val_accuracy: 0.6898\n","Epoch 20/30\n","17/17 [==============================] - 0s 13ms/step - loss: 0.2604 - accuracy: 0.5090 - val_loss: 0.2366 - val_accuracy: 0.6269\n","Epoch 21/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2602 - accuracy: 0.5117 - val_loss: 0.2383 - val_accuracy: 0.6486\n","Epoch 22/30\n","17/17 [==============================] - 0s 11ms/step - loss: 0.2603 - accuracy: 0.4900 - val_loss: 0.2379 - val_accuracy: 0.5965\n","Epoch 23/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2602 - accuracy: 0.4955 - val_loss: 0.2378 - val_accuracy: 0.6226\n","Epoch 24/30\n","17/17 [==============================] - 0s 11ms/step - loss: 0.2602 - accuracy: 0.5158 - val_loss: 0.2383 - val_accuracy: 0.6182\n","Epoch 25/30\n","17/17 [==============================] - 0s 11ms/step - loss: 0.2599 - accuracy: 0.5199 - val_loss: 0.2369 - val_accuracy: 0.6529\n","Epoch 26/30\n","17/17 [==============================] - 0s 11ms/step - loss: 0.2600 - accuracy: 0.5211 - val_loss: 0.2381 - val_accuracy: 0.6508\n","Epoch 27/30\n","17/17 [==============================] - 0s 11ms/step - loss: 0.2602 - accuracy: 0.5259 - val_loss: 0.2385 - val_accuracy: 0.5575\n","Epoch 28/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2600 - accuracy: 0.5102 - val_loss: 0.2372 - val_accuracy: 0.5141\n","Epoch 29/30\n","17/17 [==============================] - 0s 11ms/step - loss: 0.2599 - accuracy: 0.5197 - val_loss: 0.2377 - val_accuracy: 0.6594\n","Epoch 30/30\n","17/17 [==============================] - 0s 12ms/step - loss: 0.2599 - accuracy: 0.4982 - val_loss: 0.2367 - val_accuracy: 0.7007\n","Epoch 1/30\n","11/11 [==============================] - 0s 17ms/step - loss: 0.2633 - accuracy: 0.5590 - val_loss: 0.2087 - val_accuracy: 0.5748\n","Epoch 2/30\n","11/11 [==============================] - 0s 14ms/step - loss: 0.2610 - accuracy: 0.5776 - val_loss: 0.2057 - val_accuracy: 0.7993\n","Epoch 3/30\n","11/11 [==============================] - 0s 15ms/step - loss: 0.2591 - accuracy: 0.6212 - val_loss: 0.2070 - val_accuracy: 0.8231\n","Epoch 4/30\n","11/11 [==============================] - 0s 15ms/step - loss: 0.2582 - accuracy: 0.6488 - val_loss: 0.2094 - val_accuracy: 0.5952\n","Epoch 5/30\n","11/11 [==============================] - 0s 13ms/step - loss: 0.2580 - accuracy: 0.6341 - val_loss: 0.2071 - val_accuracy: 0.7857\n","Epoch 6/30\n","11/11 [==============================] - 0s 13ms/step - loss: 0.2575 - accuracy: 0.6382 - val_loss: 0.2083 - val_accuracy: 0.5952\n","Epoch 7/30\n","11/11 [==============================] - 0s 13ms/step - loss: 0.2571 - accuracy: 0.6428 - val_loss: 0.2071 - val_accuracy: 0.7381\n","Epoch 8/30\n","11/11 [==============================] - 0s 13ms/step - loss: 0.2569 - accuracy: 0.6451 - val_loss: 0.2057 - val_accuracy: 0.7279\n","Epoch 9/30\n","11/11 [==============================] - 0s 14ms/step - loss: 0.2563 - accuracy: 0.6583 - val_loss: 0.2074 - val_accuracy: 0.6599\n","Epoch 10/30\n","11/11 [==============================] - 0s 13ms/step - loss: 0.2563 - accuracy: 0.6636 - val_loss: 0.2095 - val_accuracy: 0.5816\n","Epoch 11/30\n","11/11 [==============================] - 0s 12ms/step - loss: 0.2559 - accuracy: 0.6644 - val_loss: 0.2071 - val_accuracy: 0.7279\n","Epoch 12/30\n","11/11 [==============================] - 0s 12ms/step - loss: 0.2560 - accuracy: 0.6674 - val_loss: 0.2065 - val_accuracy: 0.7007\n","Epoch 13/30\n","11/11 [==============================] - 0s 13ms/step - loss: 0.2564 - accuracy: 0.6754 - val_loss: 0.2063 - val_accuracy: 0.7857\n","Epoch 14/30\n","11/11 [==============================] - 0s 14ms/step - loss: 0.2558 - accuracy: 0.6515 - val_loss: 0.2066 - val_accuracy: 0.7245\n","Epoch 15/30\n","11/11 [==============================] - 0s 14ms/step - loss: 0.2558 - accuracy: 0.6530 - val_loss: 0.2083 - val_accuracy: 0.6769\n","Epoch 16/30\n","11/11 [==============================] - 0s 13ms/step - loss: 0.2558 - accuracy: 0.6667 - val_loss: 0.2069 - val_accuracy: 0.7551\n","Epoch 17/30\n","11/11 [==============================] - 0s 13ms/step - loss: 0.2558 - accuracy: 0.6788 - val_loss: 0.2119 - val_accuracy: 0.5646\n","Epoch 18/30\n","11/11 [==============================] - 0s 13ms/step - loss: 0.2559 - accuracy: 0.6644 - val_loss: 0.2068 - val_accuracy: 0.7619\n","Epoch 19/30\n","11/11 [==============================] - 0s 14ms/step - loss: 0.2555 - accuracy: 0.6633 - val_loss: 0.2080 - val_accuracy: 0.7075\n","Epoch 20/30\n","11/11 [==============================] - 0s 13ms/step - loss: 0.2553 - accuracy: 0.6743 - val_loss: 0.2077 - val_accuracy: 0.6156\n","Epoch 21/30\n","11/11 [==============================] - 0s 12ms/step - loss: 0.2552 - accuracy: 0.6682 - val_loss: 0.2085 - val_accuracy: 0.6531\n","Epoch 22/30\n","11/11 [==============================] - 0s 12ms/step - loss: 0.2550 - accuracy: 0.6739 - val_loss: 0.2074 - val_accuracy: 0.7007\n","Epoch 23/30\n","11/11 [==============================] - 0s 12ms/step - loss: 0.2552 - accuracy: 0.6515 - val_loss: 0.2084 - val_accuracy: 0.6020\n","Epoch 24/30\n","11/11 [==============================] - 0s 13ms/step - loss: 0.2549 - accuracy: 0.6780 - val_loss: 0.2078 - val_accuracy: 0.6531\n","Epoch 25/30\n","11/11 [==============================] - 0s 13ms/step - loss: 0.2549 - accuracy: 0.6731 - val_loss: 0.2090 - val_accuracy: 0.6633\n","Epoch 26/30\n","11/11 [==============================] - 0s 13ms/step - loss: 0.2551 - accuracy: 0.6875 - val_loss: 0.2081 - val_accuracy: 0.5578\n","Epoch 27/30\n","11/11 [==============================] - 0s 12ms/step - loss: 0.2548 - accuracy: 0.6796 - val_loss: 0.2072 - val_accuracy: 0.6735\n","Epoch 28/30\n","11/11 [==============================] - 0s 13ms/step - loss: 0.2548 - accuracy: 0.6826 - val_loss: 0.2085 - val_accuracy: 0.5170\n","Epoch 29/30\n","11/11 [==============================] - 0s 13ms/step - loss: 0.2546 - accuracy: 0.6841 - val_loss: 0.2075 - val_accuracy: 0.6939\n","Epoch 30/30\n","11/11 [==============================] - 0s 13ms/step - loss: 0.2550 - accuracy: 0.6830 - val_loss: 0.2113 - val_accuracy: 0.5238\n","Epoch 1/30\n","15/15 [==============================] - 0s 15ms/step - loss: 0.2430 - accuracy: 0.5945 - val_loss: 0.2141 - val_accuracy: 0.5464\n","Epoch 2/30\n","15/15 [==============================] - 0s 12ms/step - loss: 0.2412 - accuracy: 0.6633 - val_loss: 0.2144 - val_accuracy: 0.4411\n","Epoch 3/30\n","15/15 [==============================] - 0s 12ms/step - loss: 0.2390 - accuracy: 0.6837 - val_loss: 0.2114 - val_accuracy: 0.5038\n","Epoch 4/30\n","15/15 [==============================] - 0s 12ms/step - loss: 0.2380 - accuracy: 0.6984 - val_loss: 0.2154 - val_accuracy: 0.4060\n","Epoch 5/30\n","15/15 [==============================] - 0s 12ms/step - loss: 0.2381 - accuracy: 0.6956 - val_loss: 0.2106 - val_accuracy: 0.6717\n","Epoch 6/30\n","15/15 [==============================] - 0s 13ms/step - loss: 0.2402 - accuracy: 0.6508 - val_loss: 0.2118 - val_accuracy: 0.6015\n","Epoch 7/30\n","15/15 [==============================] - 0s 12ms/step - loss: 0.2390 - accuracy: 0.6942 - val_loss: 0.2140 - val_accuracy: 0.5714\n","Epoch 8/30\n","15/15 [==============================] - 0s 12ms/step - loss: 0.2383 - accuracy: 0.6976 - val_loss: 0.2173 - val_accuracy: 0.4010\n","Epoch 9/30\n","15/15 [==============================] - 0s 12ms/step - loss: 0.2383 - accuracy: 0.7034 - val_loss: 0.2104 - val_accuracy: 0.6842\n","Epoch 10/30\n","15/15 [==============================] - 0s 11ms/step - loss: 0.2374 - accuracy: 0.7076 - val_loss: 0.2155 - val_accuracy: 0.5038\n","Epoch 11/30\n","15/15 [==============================] - 0s 11ms/step - loss: 0.2378 - accuracy: 0.6923 - val_loss: 0.2127 - val_accuracy: 0.4586\n","Epoch 12/30\n","15/15 [==============================] - 0s 11ms/step - loss: 0.2384 - accuracy: 0.6820 - val_loss: 0.2169 - val_accuracy: 0.4261\n","Epoch 13/30\n","15/15 [==============================] - 0s 12ms/step - loss: 0.2376 - accuracy: 0.7001 - val_loss: 0.2119 - val_accuracy: 0.5789\n","Epoch 14/30\n","15/15 [==============================] - 0s 11ms/step - loss: 0.2384 - accuracy: 0.6828 - val_loss: 0.2092 - val_accuracy: 0.6817\n","Epoch 15/30\n","15/15 [==============================] - 0s 13ms/step - loss: 0.2381 - accuracy: 0.6764 - val_loss: 0.2129 - val_accuracy: 0.4762\n","Epoch 16/30\n","15/15 [==============================] - 0s 12ms/step - loss: 0.2393 - accuracy: 0.6689 - val_loss: 0.2131 - val_accuracy: 0.4511\n","Epoch 17/30\n","15/15 [==============================] - 0s 11ms/step - loss: 0.2380 - accuracy: 0.7034 - val_loss: 0.2186 - val_accuracy: 0.4060\n","Epoch 18/30\n","15/15 [==============================] - 0s 11ms/step - loss: 0.2408 - accuracy: 0.6703 - val_loss: 0.2178 - val_accuracy: 0.5564\n","Epoch 19/30\n","15/15 [==============================] - 0s 11ms/step - loss: 0.2395 - accuracy: 0.6792 - val_loss: 0.2185 - val_accuracy: 0.5188\n","Epoch 20/30\n","15/15 [==============================] - 0s 12ms/step - loss: 0.2391 - accuracy: 0.6739 - val_loss: 0.2132 - val_accuracy: 0.6366\n","Epoch 21/30\n","15/15 [==============================] - 0s 11ms/step - loss: 0.2379 - accuracy: 0.6965 - val_loss: 0.2142 - val_accuracy: 0.4436\n","Epoch 22/30\n","15/15 [==============================] - 0s 11ms/step - loss: 0.2372 - accuracy: 0.7123 - val_loss: 0.2121 - val_accuracy: 0.5915\n","Epoch 23/30\n","15/15 [==============================] - 0s 11ms/step - loss: 0.2368 - accuracy: 0.7051 - val_loss: 0.2134 - val_accuracy: 0.6566\n","Epoch 24/30\n","15/15 [==============================] - 0s 12ms/step - loss: 0.2368 - accuracy: 0.7115 - val_loss: 0.2160 - val_accuracy: 0.6040\n","Epoch 25/30\n","15/15 [==============================] - 0s 12ms/step - loss: 0.2373 - accuracy: 0.7079 - val_loss: 0.2114 - val_accuracy: 0.5113\n","Epoch 26/30\n","15/15 [==============================] - 0s 12ms/step - loss: 0.2369 - accuracy: 0.6990 - val_loss: 0.2157 - val_accuracy: 0.5539\n","Epoch 27/30\n","15/15 [==============================] - 0s 12ms/step - loss: 0.2376 - accuracy: 0.6965 - val_loss: 0.2129 - val_accuracy: 0.5163\n","Epoch 28/30\n","15/15 [==============================] - 0s 12ms/step - loss: 0.2379 - accuracy: 0.7171 - val_loss: 0.2124 - val_accuracy: 0.5789\n","Epoch 29/30\n","15/15 [==============================] - 0s 12ms/step - loss: 0.2378 - accuracy: 0.7034 - val_loss: 0.2168 - val_accuracy: 0.4962\n","Epoch 30/30\n","15/15 [==============================] - 0s 11ms/step - loss: 0.2374 - accuracy: 0.7037 - val_loss: 0.2126 - val_accuracy: 0.5589\n"]}],"source":["rewards = []\n","rewards2 = []\n","for i in range(10):\n","    ep = random.choice(demos)\n","\n","    # read the model xml, using the metadata stored in the attribute for this episode\n","    model_file = f[\"data/{}\".format(ep)].attrs[\"model_file\"]\n","    model_path = os.path.join(demo_path, \"models\", model_file)\n","    with open(model_path, \"r\") as model_f:\n","        model_xml = model_f.read()\n","\n","    states = f[\"data/{}/states\".format(ep)][()]\n","\n","    jvels = f[\"data/{}/joint_velocities\".format(ep)][()]\n","    grip_acts = f[\"data/{}/gripper_actuations\".format(ep)][()]\n","    actions = np.concatenate([jvels, grip_acts], axis=1)\n","    num_actions = actions.shape[0]\n","    ep_rewards = []\n","    tf_model.fit(states, actions, batch_size=256, validation_split=0.1, epochs=30)\n","    \n","    '''\n","    Evaluation\n","    if indirect_data:\n","        for j, action in enumerate(actions):\n","            state = env.sim.get_state().flatten()\n","            state = np.array([state])\n","            predicted = tf_model.predict(state)\n","            predicted = np.squeeze(predicted)\n","            obs, reward, done, _  = env.step(predicted)\n","            ep_rewards.append(reward)\n","            if done:\n","                break\n","    else:\n","        for state, action in zip(states, actions):\n","            env.sim.set_state_from_flattened(state)\n","            env.sim.forward()\n","            ep_rewards.append(env.reward(action))\n","    \n","    rewards.append(ep_rewards)\n","    '''\n"]},{"cell_type":"code","execution_count":41,"metadata":{"scrolled":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2023-05-03 03:19:23.462507: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,512]\n","\t [[{{node inputs}}]]\n","2023-05-03 03:19:23.481662: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,256]\n","\t [[{{node inputs}}]]\n","2023-05-03 03:19:23.708530: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,512]\n","\t [[{{node inputs}}]]\n","2023-05-03 03:19:23.752011: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,256]\n","\t [[{{node inputs}}]]\n","WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: /home/ar4451/tf/il/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: /home/ar4451/tf/il/assets\n"]}],"source":["tf_model.save('/home/ar4451/tf/il')"]}],"metadata":{"kernelspec":{"display_name":"myenv","language":"python","name":"myenv"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":2}